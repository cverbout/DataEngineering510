# -*- coding: utf-8 -*-
"""DataEng S24: Data Validation Activity.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZoJujeAkdafLryogEf6x5G_hc66GIpJG
"""

import pandas as pd

# URL of the CSV file
url = '/content/Hwy26Crashes2019_S23.csv'

# Read the CSV file from the URL into a DataFrame
df = pd.read_csv(url)

# Display the first few rows of the DataFrame to check it
print(df.head(15))

import pandas as pd
import numpy as np

# Load the dataset
url = '/content/Hwy26Crashes2019_S23.csv'
df = pd.read_csv(url)

# EXISTENCE ASSERTIONS
# Check that every crash occurred on a date
assert df['Crash Day'].notnull().all()
assert df['Crash Month'].notnull().all()

# Check that every crash has an ID
assert df['Crash ID'].notnull().all()

# Check that every crash has a Vehicle ID
assert df['Vehicle ID'].notnull().all()

# LIMIT ASSERTIONS
# Check that every weekday is between 1 and 7
assert df['Week Day Code'].between(1, 7).all()

# Check that every crash month is between 1 and 12
assert df['Crash Month'].between(1, 12).all()

# INTRA-RECORD ASSERTIONS
# If a crash record has a crash day, it should have a crash month
assert np.all(df[df['Crash Day'].notnull()]['Crash Month'].notnull())
# If a crash record has a crash Month, it should have a crash year
assert np.all(df[df['Crash Month'].notnull()]['Crash Year'].notnull())

# INTER-RECORD CHECKS
# Check that every Vehicle ID has a known Participant ID
assert df.set_index('Vehicle ID')['Participant ID'].notnull().all()

# SUMMARY ASSERTIONS
# Assert there are thousands but not millions of participants
participant_count = df['Participant ID'].nunique()
assert 1000 <= participant_count < 1000000

# Check uniqueness of (Crash ID, Record Type, Vehicle ID)
assert df[['Crash ID', 'Record Type', 'Vehicle ID']].drop_duplicates().shape[0] == df.shape[0]

# STATISTICAL DISTRIBUTION ASSERTIONS
# Check if Participant ID and Vehicle ID counts are roughly the same
participant_count = df['Participant ID'].count()
vehicle_count = df['Vehicle ID'].count()
assert abs(participant_count - vehicle_count) < max(participant_count, vehicle_count) * 0.1

# Check if crashes are evenly distributed throughout the days of the week
days_distribution = df['Crash Day'].value_counts(normalize=True)
assert np.allclose(days_distribution, 1/7, atol=0.03)

print("All assertions passed.")

df_type1 = df[df['Record Type'] == 1]
df_type2 = df[df['Record Type'] == 2]
df_type3 = df[df['Record Type'] == 3]

# EXISTENCE ASSERTIONS

# Check that every crash has an ID
assert df['Crash ID'].notnull().all()
assert df_type2['Vehicle ID'].notnull().all()

# Check that every crash of type 1 occurred on a date
assert df_type1['Crash Day'].notnull().all()
assert df_type1['Crash Month'].notnull().all()

# LIMIT ASSERTIONS
# Check that every weekday is between 1 and 7
assert df_type1['Week Day Code'].between(1, 7).all()
assert df_type1['Crash Month'].between(1, 12).all()

# INTRA-RECORD ASSERTIONS
# If a crash record has a crash day, it should have a crash month
assert df[df['Crash Day'].notnull()]['Crash Month'].notnull().all()
# If a crash record has a crash Month, it should have a crash year
assert df[df['Crash Month'].notnull()]['Crash Year'].notnull().all()

# INTER-RECORD CHECKS
# Check that every Vehicle ID has a known Participant ID
assert df_type3.set_index('Vehicle ID')['Participant ID'].notnull().all()

# Check that each Vehicle ID in records where both are present has at least one corresponding Participant ID
vehicle_participant_check = df.dropna(subset=['Vehicle ID', 'Participant ID'])
grouped = vehicle_participant_check.groupby('Vehicle ID')['Participant ID'].nunique()
assert (grouped > 0).all()

# SUMMARY ASSERTIONS
# Assert there are thousands but not millions of participants
participant_count = df['Participant ID'].nunique()
assert 1000 <= participant_count < 1000000

# Check uniqueness of (Crash ID, Record Type, Vehicle ID)
assert df[['Crash ID', 'Record Type', 'Vehicle ID', "Participant ID"]].drop_duplicates().shape[0] == df.shape[0]

# STATISTICAL DISTRIBUTION ASSERTIONS
# Check if crashes are evenly distributed throughout the days of the week
days_distribution = df['Week Day Code'].value_counts(normalize=True)
assert np.allclose(days_distribution, 1/7, atol=0.03)

# Check if crashes are evenly distributed throughout the days of the week
days_distribution = df['Crash Day'].value_counts(normalize=True)
assert np.allclose(days_distribution, 1/31, atol=0.03)


print("All assertions passed.")

import pandas as pd
url = '/content/Hwy26Crashes2019_S23.csv'
df = pd.read_csv(url)
record_types = df['Record Type'].unique()

for record_type in record_types:
    df_subset = df[df['Record Type'] == record_type]
    filename = f'record_type_{record_type}_data.csv'
    df_subset.to_csv(filename, index=False)
    print(f'Saved {filename} with {len(df_subset)} records')

url = '/content/record_type_1_data.csv'
df_type1 = pd.read_csv(url)
df_type1.head()

url = '/content/record_type_2_data.csv'
df_type2 = pd.read_csv(url)
df_type2.head()

url = '/content/record_type_3_data.csv'
df_type3 = pd.read_csv(url)
df_type3.head()

